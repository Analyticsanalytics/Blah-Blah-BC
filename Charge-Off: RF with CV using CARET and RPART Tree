


#########################   Accuracy 77%. 14/18 Correct....  AUC is 78%    ########################################


rm(list = ls())
setwd("C:\\Users\\sohail.ahmad\\Desktop\\Charge-off Pattern\\New_22nd May")
df = read.csv("imputed.csv")
names(df)
df$Chargeoff_2 = as.factor(df$Chargeoff_2)
df$Total = NULL
df$Term = NULL

set.seed(100)
spl = sample(nrow(df), 0.7*nrow(df))
train = df[spl,]
test = df[-spl,]

library(DMwR)
set.seed(100)
train1 = SMOTE(Chargeoff_2 ~ ., train, perc.over = 100, perc.under=300)
table(train1$Chargeoff_2)
table(test$Chargeoff_2)

#We need to loads caret & e1071 packages to use cross-validation
library(lattice)
library(ggplot2)
library(caret)
library(e1071)
library(rpart)
library(rpart.plot)

#Deciding how many folds we wanna use. 10 folds we wanna use. CV means cross validation
numFolds = trainControl(method="cv", number=10)
summary(numFolds)

#In 10-fold cross validation, the model will make 10 training data (folds) of training set, each fold containing 10% of
#the data, the model will be estimate cp values on 9 folds (k-1 folds or 90% of the data) with replacement and estimate the cp on
#the 1 fold (10% of data) with repeatation.We'll repeat this for 10 folds and then compuet cp values. We'll take avg cp value of all these models
#and then make a CART tree using this cp value



#Possible values of cp parameters using expand.grid function
cpGrid = expand.grid(.cp=seq(0.01, 0.5, 0.01)) #From 0.01 to 0.5 with increment of 0.01


#We do cross-validation using "train" function.trControl is the output of train function
set.seed(100)
train(Chargeoff_2 ~ ., data=train1, method="rpart", trControl=numFolds, tuneGrid=cpGrid)
#1st column gives the cp values. 2nd column give the accuracy of cp value. Accuracy starts lower, then increase and then decreses again
#cp=0.18 in video but m getting cp=0.06. Lets use cv=0.18
colSums(is.na(train1))

#We're creating a new CART model using this cp value instead of minbucket parameter
StevensTreeCV = rpart(Chargeoff_2 ~ ., data=train1, method="class", cp=0.08)
prp(StevensTreeCV)
PredictCV = predict(StevensTreeCV, newdata=test, type="class")

#Confusion matrix. Accuracy rate is 72%. It was 65.9% in our previous CART model
table(test$Chargeoff_2, PredictCV)
#Cross validation helps us make sure we're choosing the good parameter value

#################################################################################################################################################


rm(list = ls())
df = read.csv("imputed.csv")
names(df)
df$Chargeoff_2 = as.factor(df$Chargeoff_2)

set.seed(100)
spl = sample(nrow(df), 0.7*nrow(df))
train = df[spl,]
test = df[-spl,]


library(rpart)
library(rpart.plot)
library(caret)
library(tidyverse)
library(DMwR)
set.seed(100)
train1 = SMOTE(Chargeoff_2 ~ ., train, perc.over = 100, perc.under=300)

table(train1$Chargeoff_2)
table(test$Chargeoff_2)

set.seed(100)
model_rf = train(Chargeoff_2 ~., data=train1, method="rf", trControl=trainControl(method = "cv",
                  number = 10, repeats = 10, verboseIter =TRUE))

model_rf$results$Kappa

set.seed(100)
predictions_rf = predict(model_rf, test)
postResample(pred = predictions_rf, test$Chargeoff_2)

# Precision is 73%. Overall accuracy is 85%
table(test$Chargeoff_2, predictions_rf)
table(test$Chargeoff_2)

# ROC is 80%
library(ROSE)
roc.curve(test$Chargeoff_2, predictions_rf)


